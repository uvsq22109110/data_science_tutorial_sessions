1. 2D Convolutions are instrumental when creating convolutional neural networks or just for **general image processing filters** such as blurring, sharpening, edge detection, and many more. They are based on the idea of using a kernel and iterating through an input image to create an output image. A kernel, which is simply a **small matrix of weights**, **slides** over the 2D input data, performing an elementwise multiplication with the part of the input it is currently on, and then summing up the results into a **single** output pixel. This output is called **Feature map**.

<div style="height:400px;text-align: center;">
    <img style="height:200px;" src="https://miro.medium.com/max/1000/1*8dx6nxpUh2JqvYWPadTwMQ.gif" />
    <p>then</p>
    <img style="height:180px;" src="https://miro.medium.com/max/1000/1*CYB2dyR3EhFs1xNLK8ewiA.gif" />
</div>

2. Padding & Stride are two techniques used in convolutional neural network.

    A. Padding : Padding refers to the amount of pixels added to an image when it is being processed by the kernel. </br>
    B. Stride  : Stride is the number of pixels shifts over the input matrix. When the stride is 1 then we move the filters to 1 pixel at a time. When the stride is 2 then we move the filters to 2 pixels at a time and so on. The below figure shows convolution would work with a stride of 2.

<div style="height:200px;text-align: center;">
    <img style="float:0.1;height:200px;" src="https://vishalj7.github.io/images/cnn/cnn_padding.gif" />
    <img style="float:right;height:200px;" src="https://csdl-images.computer.org/trans/si/2020/04/figures/ko1ab-2961602.gif" />
</div>

* We distinguish many types of padding
    
    - Valid padding : Known also as **no padding**, we do not modify the input.
    - Same padding  : known also as **zero padding**. This padding ensures that the output has the same shape as the input data by **adding zero pixel** to the original input image.
    - Constant padding : is a type of **same padding** but we **replace zeros by a constant**
    - Reflection padding : Known also as **mirror padding or replication padding**. It pads the values with the reflection of the values directly in the opposite direction of the edge of your to be padded shape.
    
3. Padding help us to avoid 
    * Shrinking outputs : When we are appying multiple convolutions without padding the input size at each layer become smaller.
    * Loosing information on corners of the image : When we do not apply padding padding to input image we are loosing informations of the pixel near the borders. 
    
4. The rule to compute the output dimension 

<div style="height:200px;text-align: center;">
    <img style="height:200px;" src="https://miro.medium.com/max/330/1*V5ZIZg7cGHLASKbnRbKBJQ.png" />
</div>


5. Pooling is a function which progressively reduce the spatial size of the representation. It reduces the amount of parameters and computation in the network. Pooling layer operates on each feature map independently. It summarises the features present in a region of the feature map generated by a convolution layer. So, later other operations in the CNN are done on summarized features which make the model more robust to variations in the position of the features in the input image.
    * Max Pooling : It selects the maximum element from the region of the feature map covered by the filter. Thus, the output after max-pooling layer would be a feature map containing the most prominent features of the previous feature map.

    * Average Pooling : It computes the average of the elements present in the region of feature map covered by the filter. Thus, while max pooling gives the most prominent feature in a particular patch of the feature map, average pooling gives the average of features present in a patch.

<div style="height:150px;">
    <img style="float:left;height:150px;width:500px;" src="https://media.geeksforgeeks.org/wp-content/uploads/20190721025744/Screenshot-2019-07-21-at-2.57.13-AM.png" />
    <img style="float:right;height:150px;width:500px;" src="https://media.geeksforgeeks.org/wp-content/uploads/20190721030705/Screenshot-2019-07-21-at-3.05.56-AM.png" />
</div>

6. The term **dropout** refers to dropping out units (both hidden and visible) in a neural network. Simply put, dropout refers to **ignoring units** (i.e. neurons) during the **training** phase of certain set (with a probability p) of neurons which is chosen at random. When **Testing** all units are active, so **we rescale the output using the probability p to get the same magnitude of value in activation**. Dropout is known as a **different technique for regularization**. Unlike L1 and L2 regularization, dropout **doesn't rely on modifying the **cost function**. Instead, in dropout we **modify the network itself**. Another advantage when using dropout, we will prevent all the neurons from converging to the same goal by synchronously optimizing their weights, **known as co-adaptation**.

<div style="height:200px;text-align: center;">
    <img style="height:200px;" src="http://wantee.github.io/assets/images/posts/Dropout.png" />
</div>

7. A bounding box is an imaginary rectangle that serves as a point of reference for object detection and creates a collision box for that object.
8. We could perform many tasks using CNN:

    - **Classification**: CNN could be used to perform classfication of images or text (Sentiment Analysis for example). The main goal is to output a label for a class with a probability of confidence.
    - **Object Localization** : In this case, CNN will try to find an object in an image and output a bouding box which covers the object.
    - **Object Detection** : In this type of CNN, we'll detect many objects in an image. The model output a list of bounding boxes and a class (label) for each bounding box.
    - **Image Segmentation** : In this type of model the goal in to output an image with mask (label) per pixel. So you can identify exactly the object using the masks. It is also known as a pixel-to-pixel classification.
    
9. This filter is a high-pass filter. In this kernel, the pixel is boosted when the neighbor pixels are different.
